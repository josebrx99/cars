{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from lxml import html\n",
    "import time\n",
    "from datetime import datetime\n",
    "from unidecode import unidecode\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd().replace(\"\\\\\",\"/\")[:-4])\n",
    "import models\n",
    "import functions as func\n",
    "import paths as ph\n",
    "\n",
    "sys.path.append(os.getcwd().replace(\"\\\\\",\"/\") + \"/src\")\n",
    "import homologations as ho\n",
    "import spider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloque 4: concatenado final de archivos\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'paths' has no attribute 'temp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m models_homologue \u001b[38;5;241m=\u001b[39m ho\u001b[38;5;241m.\u001b[39mmodels_homologue\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBloque 4: concatenado final de archivos\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mReadTemp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestado\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m120\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users/Usuario/Desktop/cars-main/car/src\\spider.py:741\u001b[0m, in \u001b[0;36mReadTemp\u001b[1;34m()\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mReadTemp\u001b[39m():\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m--> 741\u001b[0m     files \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[43mph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemp\u001b[49m)\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m#files = [pd.read_csv(\"temp/\" + x, sep = \"|\") for x in files]\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'paths' has no attribute 'temp'"
     ]
    }
   ],
   "source": [
    "# Concatenar sin scrappear\n",
    "oferts_urls = []\n",
    "urls_complete = []\n",
    "\n",
    "RefineAtributes = spider.RefineAtributes\n",
    "ReadTemp = spider.ReadTemp\n",
    "TrainModel = spider.TrainModel\n",
    "models_homologue = ho.models_homologue\n",
    "\n",
    "print(\"Bloque 4: concatenado final de archivos\")\n",
    "df = ReadTemp()\n",
    "df = df[df[\"estado\"] == 1]\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(\"Bloque 5: refinando atributos\")\n",
    "df = RefineAtributes(df)\n",
    "print(\"-\"*120)\n",
    "\n",
    "\n",
    "print(\"Correctos final:\", df[df[\"estado\"] == 1].shape[0], \"|\", round((df[df[\"estado\"] == 1].shape[0]/df.shape[0])*100, 2), \"%\")\n",
    "print(\"Dimensión df:\", df.shape)\n",
    "vars_duplicates = [\"marca\", \"modelo\", \"precio\", \"año\", \"motor\", \"km\", \"transmision\", \"tipo_de_carroceria\", \"tipo_de_combustible\", \n",
    "                \"barrio\", \"ciudad\", \"departamento\"]\n",
    "print(\"Duplicados por atributos:\", df[df.duplicated(vars_duplicates)].shape[0])\n",
    "print(\"Duplicados por url:\", df[df.duplicated([\"url\"])].shape[0])\n",
    "print(\"Duplicados por id:\", df[df.duplicated([\"id_ofert\"])].shape[0])\n",
    "df = df.drop_duplicates(\"url\").drop_duplicates(\"id_ofert\").drop_duplicates(vars_duplicates)\n",
    "print(\"Dimensión df sin duplicados:\", df.shape)\n",
    "print(\"-\"*120)\n",
    "pendient = set(oferts_urls) - set(df[\"url\"])\n",
    "print(\"Final: Registros correctos:\", len(urls_complete))\n",
    "print(\"Final: Registros con error (excluidos):\", len(pendient))\n",
    "print(\"=\"*120)\n",
    "\n",
    "\n",
    "print(\"Bloque 6: imputación de datos faltantes en categoricas\"); print(\"-\"*50)\n",
    "df = models.ImputCategorics(df, \"marca_modelo\", \"transmision\", 70)\n",
    "df = models.ImputCategorics(df, \"marca_modelo\", \"tipo_de_carroceria\", 70)\n",
    "df = models.ImputCategorics(df, \"marca_modelo\", \"tipo_de_combustible\", 70)\n",
    "df = models.ImputCategorics(df, \"marca_modelo\", \"puertas\", 70)\n",
    "print(\"=\"*120)\n",
    "\n",
    "\n",
    "# df[\"transmision\"] = df[\"transmision\"].fillna(\"NULO\")\n",
    "# df[\"tipo_de_carroceria\"] = df[\"tipo_de_carroceria\"].fillna(\"NULO\")\n",
    "# df[\"tipo_de_combustible\"] = df[\"tipo_de_combustible\"].fillna(\"NULO\")\n",
    "\n",
    "print(\"Bloque 7: imputando valores faltantes en cilindraje\"); print(\"-\"*50)\n",
    "df[\"motor\"] = np.log(df[\"motor\"])\n",
    "df = models.ImputRegression(df, y = 'motor', x = ['año', 'marca', 'modelo', 'tipo_de_combustible', 'transmision', 'tipo_de_carroceria', \n",
    "                                                'puertas'], method = \"xgboost\")\n",
    "df[\"motor\"] = round(np.exp(df[\"motor\"]), 2)\n",
    "print(\"=\"*120)\n",
    "\n",
    "\n",
    "print(\"Bloque 8: criterios de exclusión e inclusión\"); print(\"-\"*50)\n",
    "df = spider.Criterios(df)\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(\"Bloque 9: agrupacion de variables\"); print(\"-\"*50)\n",
    "# df = models.ClassicationTreeGroup(df, y = \"precio\", x = \"marca\", max_leaf_nodes=[4, 5, 6]); print(\"-\"*50)\n",
    "df = models.ClassicationTreeGroup(df, y = \"precio\", x = \"modelo\", max_leaf_nodes=[25])\n",
    "print(\"=\"*120)\n",
    "\n",
    "df = df[['estado', 'nombre', 'precio', 'año', 'km', 'km_por_año', 'barrio', 'ciudad','departamento', 'fecha', 'url', 'dtm_etl', \n",
    "        'marca_modelo', 'marca', \n",
    "        'modelo', 'modelo_agrup', 'version','color', 'tipo_de_combustible', 'puertas', 'transmision', 'motor','tipo_de_carroceria', \n",
    "        'ultimo_digito_de_la_placa','con_camara_de_reversa']]\n",
    "\n",
    "#df.to_csv(\"df_refine.csv\", sep = \"|\", index = False)\n",
    "df.to_parquet(\"data/df_refine.parquet\", compression = \"gzip\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(\"---------- Precio ----------\")\n",
    "print(\"Media:\", round(df[\"precio\"].mean(), 2))\n",
    "print(\"Mediana:\", round(df[\"precio\"].median(), 2))\n",
    "print(\"CV:\", round(np.sqrt(df[\"precio\"].var()) / df[\"precio\"].mean() * 100, 2), \"%\")\n",
    "#print(\"Umbral:\", round(umbral_precio, 3))\n",
    "print(\"=\"*120)\n",
    "\n",
    "print(\"Bloque 10: entrenando modelo predictivo\"); print(\"-\"*50)\n",
    "model = TrainModel(df, save_model = True)\n",
    "\n",
    "print(\"Dimensión final:\", df.shape)\n",
    "print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': 'gbtree',\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': 0.7999999999999999,\n",
       " 'device': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': 10,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': 12,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'multi_strategy': None,\n",
       " 'n_estimators': 425,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': 1,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'alpha': 0.45,\n",
       " 'eta': 0,\n",
       " 'lambda': 0.5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m func\u001b[38;5;241m.\u001b[39mpkl\u001b[38;5;241m.\u001b[39mSave(model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mph\u001b[49m\u001b[38;5;241m.\u001b[39mmodels_pkl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/xgboost_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(actual_date)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ph' is not defined"
     ]
    }
   ],
   "source": [
    "func.pkl.Save(model, f'{ph.models_pkl}/xgboost_{str(actual_date)}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "año = 2005\n",
    "km = 150000\n",
    "motor = 4\n",
    "marca = \"Ford\"\n",
    "modelo = \"Explorer\"\n",
    "tipo_de_carroceria = \"Camioneta\"\n",
    "puertas = \"4_5\"\n",
    "transmision = \"Automático\"\n",
    "tipo_de_combustible = \"Gasolina\"\n",
    "modelo = df[df[\"modelo\"] == modelo][\"modelo_agrup\"].unique()[0]\n",
    "\n",
    "import joblib\n",
    "files_models = sorted(os.listdir(\"models_pkl\"))[-1]\n",
    "model = joblib.load(\"models_pkl/\" + files_models)  \n",
    "\n",
    "cols_numeric = [\"precio\", \"año\", \"km\", \"motor\", \"km_por_año\"]\n",
    "for col in cols_numeric:\n",
    "    df[col] = df[col].astype(float)\n",
    "df_train = df[[\"precio\", \"año\", \"km\", \"motor\", \"km_por_año\", \"transmision\", \"tipo_de_combustible\", \"tipo_de_carroceria\", \"puertas\",\n",
    "                \"marca\", \"modelo_agrup\"]].dropna()\n",
    "df_train[\"precio\"] = np.log(df_train[\"precio\"].astype(float))\n",
    "\n",
    "dim_models = func.pkl.Load(\"pkl/dim_models_group.pkl\")[[\"modelo\", \"modelo_agrup\"]].drop_duplicates()\n",
    "dim_doors = func.pkl.Load(\"pkl/dim_models_group.pkl\")[[\"modelo\", \"puertas\"]].drop_duplicates()\n",
    "\n",
    "modelo = dim_models[dim_models[\"modelo\"] == modelo][\"modelo_agrup\"].unique()[0]\n",
    "puertas = dim_doors[dim_doors[\"modelo\"] == modelo][\"puertas\"].unique().tolist()\n",
    "\n",
    "if puertas == []:\n",
    "    puertas = \"4_5\"\n",
    "else:\n",
    "    puertas = puertas[0]\n",
    "df_new = pd.DataFrame({\"año\":[año], \"km\":[km], \"motor\":[motor], \"km_por_año\":[km/(datetime.today().year-año)], \n",
    "                        \"transmision\":[transmision], \"tipo_de_combustible\":[tipo_de_combustible],\"marca\":[marca], \n",
    "                        \"modelo_agrup\":[modelo], \"puertas\":[puertas], \"tipo_de_carroceria\":[tipo_de_carroceria]})\n",
    "df_new = pd.get_dummies(df_new, columns = [\"transmision\", \"tipo_de_combustible\", \"marca\", \"modelo_agrup\",\n",
    "                                            \"puertas\", \"tipo_de_carroceria\"]).replace(True, 1)\n",
    "\n",
    "df_predict = pd.DataFrame(columns = model.feature_names_in_)\n",
    "df_predict.loc[0] = 0\n",
    "features = model.feature_names_in_.tolist()\n",
    "features_delete = list(set(df_new.columns) - set(features))\n",
    "if features_delete != []:\n",
    "    df_predict.drop(columns = features_delete, inplace = True)\n",
    "\n",
    "predict = int(np.exp(model.predict(features_delete))*1000000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
